# The battle for ethical AI at the world’s biggest machine-learning conference
## criado em: 19:54 26-01-2023

### Relacionado
- palavras-chave: #promptgpt3 #meta #zettelkasten #1000palavrasoumais #disserte #newsletter #ceticismo #escrita #filosofia #mestredeculturacontemporanea #totalizante #criatividade #episteme 
- notas: [[pedi o chat gpt que recomendasse pentiment para um amigo de férias]]
- [[Content, por Kate Eichorn]]
- [[its the content killing the culture - wisecrack edition]]
- [[A ascensão da indústria de conteúdo]]
- [[teoria da cauda longa e a indústria do conteúdo]]
- [[filosofia da tecnologia]]
- notas: [[Don’t ask if artificial intelligence is good or fair, ask how it shifts power]]
- [[radical AI network]]
- [[ALARMADOS PELO GPT3, UNIVERSIDADES COMEÇAM E REVISAR SUA FORMA DE ENSINAR - artigo]]
---
[fonte](https://www.nature.com/articles/d41586-020-00160-y)
Artigo de 2020

# A batalha pela IA ética na maior conferência mundial de aprendizagem mecânica

## O preconceito e a perspectiva de danos societais cada vez mais pesada investigação de inteligência artificial - mas não é claro quem deve estar atento a estes problemas.

- A ética e o potencial de danos societais na investigação da IA foram o foco principal da conferência Neural Information Processing Systems (NeurIPS) em 2018. 
- Há uma percepção crescente entre os investigadores de que precisam de incorporar a ética na sua investigação e considerar os potenciais danos da injustiça algorítmica. 
- A ética não é actualmente um foco específico do processo de revisão de trabalhos submetidos ao NeurIPS e outras grandes conferências sobre IA. 
- As soluções potenciais incluem a introdução da revisão ética em conferências, pedir aos autores que façam uma declaração sobre a ética do seu trabalho, e formar revisores para detectar violações de ética. 
- O AI Now Institute solicita que todos os trabalhos de investigação de aprendizagem por máquinas incluam uma secção sobre danos societais e a proveniência dos seus conjuntos de dados. 
- As empresas de tecnologia estão a abordar a ética do seu trabalho de AI, mas os activistas argumentam que não lhes deve ser permitido "lavar a ética" e que as pessoas dos grupos afectados devem ser incluídas nos conselhos de ética para assegurar que o contexto é tido em conta quando se discute a tecnologia.

