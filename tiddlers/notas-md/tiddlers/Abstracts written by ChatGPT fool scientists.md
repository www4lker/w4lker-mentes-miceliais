# abstracts fooling scientists
## criado em: 19:37 26-01-2023

### Relacionado
- palavras-chave: #promptgpt3 #meta #zettelkasten #1000palavrasoumais #disserte #newsletter #ceticismo #escrita #filosofia #mestredeculturacontemporanea #totalizante #criatividade #episteme 
- notas: [pedi o chat gpt que recomendasse pentiment para um amigo de férias](pedi%20o%20chat%20gpt%20que%20recomendasse%20pentiment%20para%20um%20amigo%20de%20férias)
- [meta-prompt Article to notes](meta-prompt%20Article%20to%20notes.md)
- [Content, por Kate Eichorn](Content,%20por%20Kate%20Eichorn.md)
- [its the content killing the culture - wisecrack edition](its%20the%20content%20killing%20the%20culture%20-%20wisecrack%20edition)
- [A ascensão da indústria de conteúdo](A%20ascensão%20da%20indústria%20de%20conteúdo)
- [teoria da cauda longa e a indústria do conteúdo](teoria%20da%20cauda%20longa%20e%20a%20indústria%20do%20conteúdo)
- [filosofia da tecnologia](filosofia%20da%20tecnologia)
- [Ferramentas como o ChatGPT ameaçam a ciência transparente - aqui estão as nossas regras básicas para a sua utilização](Ferramentas%20como%20o%20ChatGPT%20ameaçam%20a%20ciência%20transparente%20-%20aqui%20estão%20as%20nossas%20regras%20básicas%20para%20a%20sua%20utilização.md)
- [Don’t ask if artificial intelligence is good or fair, ask how it shifts power](Don’t%20ask%20if%20artificial%20intelligence%20is%20good%20or%20fair,%20ask%20how%20it%20shifts%20power.md)
---
[fonte](https://www.nature.com/articles/d41586-023-00056-7)


# Resumos escritos por ChatGPT engana cientistas

## Os investigadores nem sempre conseguem diferenciar entre resumos gerados por IA e originais.

- Uma pré-impressão publicada no servidor bioRxiv no final de Dezembro de 2020 sugere que um chatbot de IA chamado ChatGPT pode criar resumos falsos de investigação-papel que são suficientemente convincentes de que os cientistas são frequentemente incapazes de os detectar.
- Os investigadores estão divididos quanto às implicações para a ciência, tendo alguns manifestado preocupação quanto ao potencial do chatbot para enganar os cientistas e causar impacto na sociedade em geral.
- ChatGPT é um "modelo de linguagem grande" criado pelo OpenAI que gera texto realista e inteligente em resposta a solicitações dos utilizadores.
- Um grupo liderado por Catherine Gao na Northwestern University em Chicago utilizou o ChatGPT para gerar 50 resumos de investigação médica com base numa selecção publicada em várias revistas médicas e depois pediu a um grupo de investigadores médicos para localizar os resumos fabricados.
- Os resumos gerados pelo ChatGPT navegaram através do verificador de plágio e do detector de AI-output e os revisores humanos apenas identificaram correctamente 68% dos resumos gerados, apesar de o detector de AI-output ter detectado 66% dos resumos gerados.
- Os autores sugerem que aqueles que avaliam as comunicações científicas, tais como trabalhos de investigação e actas de conferências, deveriam implementar políticas para eliminar a utilização de textos gerados por IA e, se as instituições optarem por permitir a utilização da tecnologia em certos casos, deveriam estabelecer regras claras em torno da divulgação.
- ==alguns peritos sugerem que a solução para estas questões não deve centrar-se no chatbot em si, mas sim nos incentivos perversos que conduzem a este comportamento, tais como universidades que conduzem revisões de contratação e promoção, contando os trabalhos sem qualquer consideração pela sua qualidade ou impacto===. [[A pirâmide financeira da carreira académica]

A última observação feita no texto é que as soluções para as questões relacionadas com a utilização de textos gerados por IA na investigação científica não devem centrar-se no chatbot em si, mas sim nos factores subjacentes que conduzem a este comportamento. Isto inclui ==abordar os incentivos perversos que existem dentro do sistema académico, tais como universidades que realizam revisões de contratação e promoção baseadas unicamente no número de artigos que um investigador publicou, sem considerar a sua qualidade ou impacto===. ==Esta pressão para publicar pode levar os investigadores a recorrer a práticas antiéticas, tais como a utilização de IA para gerar resumos falsos de trabalhos de investigação que podem ser difíceis de distinguir de textos escritos por humanos===. Para combater este problema, é importante abordar e alterar os incentivos subjacentes que impulsionam este comportamento, em vez de simplesmente tentar regular o uso de ferramentas de IA como o ChatGPT.